#!/usr/bin/env node
/**
 * Create Data Dictionaries for DKAN Sample Datasets
 *
 * This script:
 * 1. Fetches all datasets from the DKAN instance
 * 2. For each CSV distribution with datastore:
 *    - Analyzes the datastore schema
 *    - Creates a data dictionary with field definitions
 *    - Uploads the dictionary via API
 *
 * Usage:
 *   npm run create:dictionaries                    # Development (default)
 *   NODE_ENV=test npm run create:dictionaries      # Test environment
 *   NODE_ENV=production npm run create:dictionaries # Production environment
 *
 * Environment-specific configuration:
 *   .env                      # Base (auto-generated by DDEV)
 *   .env.development.local    # Personal dev overrides
 *   .env.test.local           # Test server credentials
 *   .env.production.local     # Production server credentials
 *
 * Shell overrides (always highest priority):
 *   DKAN_URL=https://demo.getdkan.org npm run create:dictionaries
 */

import { config } from 'dotenv'
import { parse } from 'csv-parse/sync'
import { join, dirname } from 'path'
import { fileURLToPath } from 'url'
import { DkanApiClient } from '../src/api/client'
import type { DkanDataset, DataDictionary, DataDictionaryField } from '../src/types'

// Load environment variables from .env files in project root
// Supports multiple environments: development, test, production
//
// Loading priority (highest to lowest):
// 1. Shell environment variables (always highest priority)
// 2. .env.${NODE_ENV}.local (personal environment overrides)
// 3. .env.${NODE_ENV} (environment-specific config)
// 4. .env.local (personal defaults)
// 5. .env (base config - auto-generated by DDEV)
//
// @ts-expect-error - import.meta is valid in Node ESM (see tsconfig.scripts.json)
const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)
const projectRoot = join(__dirname, '../../..')
const NODE_ENV = process.env.NODE_ENV || 'development'

// Load in reverse priority order (with override: false, first loaded wins)
// Shell vars are already loaded and will never be overridden
config({ path: join(projectRoot, `.env.${NODE_ENV}.local`), override: false })
config({ path: join(projectRoot, `.env.${NODE_ENV}`), override: false })
config({ path: join(projectRoot, '.env.local'), override: false })
config({ path: join(projectRoot, '.env'), override: false })

const DKAN_URL = process.env.DKAN_URL || 'http://dkan.ddev.site'
const DKAN_USER = process.env.DKAN_USER
const DKAN_PASS = process.env.DKAN_PASS

// Validate credentials (required for creating data dictionaries)
if (!DKAN_USER || !DKAN_PASS) {
  console.error('\n‚ùå Error: DKAN_USER and DKAN_PASS must be set')
  console.error('\nTo fix this:')
  console.error('  1. Ensure DKAN setup has been run: cd dkan && ddev exec bash scripts/setup-site.sh')
  console.error('  2. Check that .env file exists in project root with API credentials')
  console.error('  3. API credentials are auto-generated during DKAN setup\n')
  process.exit(1)
}

interface DistributionWithId {
  identifier: string
  title?: string
  format?: string
  mediaType?: string
  downloadURL?: string
  datasetId: string
  datasetTitle: string
}

/**
 * Infer field type from sample values
 */
function inferFieldType(values: any[]): 'string' | 'number' | 'integer' | 'boolean' | 'date' {
  const nonNullValues = values.filter(v => v != null && v !== '')

  if (nonNullValues.length === 0) return 'string'

  // Check if all values are booleans
  if (nonNullValues.every(v => typeof v === 'boolean' || v === 'true' || v === 'false')) {
    return 'boolean'
  }

  // Check if all values are numbers
  if (nonNullValues.every(v => !isNaN(Number(v)))) {
    // Check if they're all integers
    if (nonNullValues.every(v => Number.isInteger(Number(v)))) {
      return 'integer'
    }
    return 'number'
  }

  // Check if values look like ISO 8601 dates (YYYY-MM-DD)
  // Use end-of-string anchor to avoid matching filenames like "2024-01-15_report.csv"
  const datePattern = /^\d{4}-\d{2}-\d{2}$/
  if (nonNullValues.every(v => datePattern.test(String(v)))) {
    return 'date'
  }

  return 'string'
}

/**
 * Generate human-readable title from field name
 */
function generateFieldTitle(fieldName: string): string {
  return fieldName
    .split('_')
    .map(word => word.charAt(0).toUpperCase() + word.slice(1).toLowerCase())
    .join(' ')
}

/**
 * Fetch all datasets with distribution identifiers
 */
async function fetchDatasetsWithDistributions(client: DkanApiClient): Promise<DistributionWithId[]> {
  console.log('üìã Fetching datasets...')

  const datasets = await client.listAllDatasets()
  console.log(`  Found ${datasets.length} datasets`)

  const distributions: DistributionWithId[] = []

  for (const dataset of datasets) {
    // Fetch dataset with show-reference-ids to get distribution UUIDs
    const response = await fetch(
      `${DKAN_URL}/api/1/metastore/schemas/dataset/items/${dataset.identifier}?show-reference-ids`,
      {
        headers: {
          'Authorization': DKAN_USER && DKAN_PASS
            ? `Basic ${Buffer.from(`${DKAN_USER}:${DKAN_PASS}`).toString('base64')}`
            : '',
        },
      }
    )

    if (!response.ok) continue

    const datasetWithIds = await response.json()

    if (datasetWithIds.distribution && Array.isArray(datasetWithIds.distribution)) {
      for (const dist of datasetWithIds.distribution) {
        // Get format from either dist.format or dist.data.format
        const format = dist.format || dist.data?.format
        const title = dist.title || dist.data?.title
        const mediaType = dist.mediaType || dist.data?.mediaType
        const downloadURL = dist.downloadURL || dist.data?.downloadURL

        // Only process CSV distributions with download URLs
        if (format === 'csv' && dist.identifier && downloadURL) {
          distributions.push({
            identifier: dist.identifier,
            title,
            format,
            mediaType,
            downloadURL,
            datasetId: dataset.identifier,
            datasetTitle: dataset.title,
          })
        }
      }
    }
  }

  console.log(`  Found ${distributions.length} CSV distributions\n`)
  return distributions
}

/**
 * Sanitize field name for use as a valid identifier
 * Converts to lowercase, replaces non-alphanumeric with underscores,
 * collapses multiple underscores, and trims leading/trailing underscores
 */
function sanitizeFieldName(name: string): string {
  return name
    .toLowerCase()
    .replace(/[^a-z0-9_]/g, '_')  // Replace invalid chars with underscore
    .replace(/_+/g, '_')           // Collapse multiple underscores
    .replace(/^_+|_+$/g, '')       // Trim leading/trailing underscores
    || 'field'                     // Fallback if name is empty after sanitization
}

/**
 * Parse CSV data to get field information
 * Uses proper CSV parser to handle quoted fields, commas in values, etc.
 */
function parseCSV(csvData: string): { headers: string[]; records: Record<string, string>[] } {
  try {
    // Parse CSV with proper library that handles quoted fields
    const parsed = parse(csvData, {
      columns: false,          // We'll handle headers manually
      skip_empty_lines: true,
      trim: true,
      relax_quotes: true,     // Be lenient with quote handling
      relax_column_count: true // Allow rows with different column counts
    })

    if (!parsed || parsed.length < 2) {
      return { headers: [], records: [] }
    }

    // First row is headers - sanitize them
    const rawHeaders = parsed[0] as string[]
    const headers = rawHeaders.map(h => sanitizeFieldName(h))

    // Remaining rows are data (limit to first 100 for analysis)
    const dataRows = parsed.slice(1, 101)
    const records: Record<string, string>[] = dataRows.map((row: string[]) => {
      const record: Record<string, string> = {}
      headers.forEach((header, index) => {
        record[header] = row[index] || ''
      })
      return record
    })

    return { headers, records }
  } catch (error) {
    console.error(`CSV parsing error: ${error instanceof Error ? error.message : String(error)}`)
    return { headers: [], records: [] }
  }
}

/**
 * Analyze CSV file and create field definitions
 */
async function analyzeCSV(
  downloadURL: string
): Promise<DataDictionaryField[] | null> {
  try {
    console.log(`    Downloading CSV from: ${downloadURL}`)

    // Fetch the CSV file
    const response = await fetch(downloadURL)
    if (!response.ok) {
      console.error(`    Error: HTTP ${response.status}`)
      return null
    }

    const csvData = await response.text()
    const { headers, records } = parseCSV(csvData)

    if (headers.length === 0 || records.length === 0) {
      console.error(`    Error: Could not parse CSV file`)
      return null
    }

    console.log(`    Analyzed ${headers.length} fields from ${records.length} records`)

    const fields: DataDictionaryField[] = headers.map(fieldName => {
      // Collect all values for this field
      const values = records.map(record => record[fieldName])

      // Infer type from values
      const type = inferFieldType(values)

      // Generate human-readable title
      const title = generateFieldTitle(fieldName)

      const field: DataDictionaryField = {
        name: fieldName,
        title,
        type,
      }

      // Only add format if it's a date
      if (type === 'date') {
        field.format = 'default'
      }

      return field
    })

    return fields
  } catch (error) {
    console.error(`    Error analyzing CSV: ${error instanceof Error ? error.message : String(error)}`)
    return null
  }
}

/**
 * Create data dictionary for a distribution
 */
async function createDataDictionary(
  client: DkanApiClient,
  distribution: DistributionWithId,
  fields: DataDictionaryField[]
): Promise<boolean> {
  try {
    // Generate a unique identifier for the dictionary (append -dict to distribution ID)
    const dictionaryId = `${distribution.identifier}-dict`

    const dictionary: DataDictionary = {
      identifier: dictionaryId,
      data: {
        title: distribution.title || `Data Dictionary for ${distribution.datasetTitle}`,
        fields,
      },
    }

    await client.createDataDictionary(dictionary)
    return true
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`    Error creating dictionary: ${errorMsg}`)
    return false
  }
}

/**
 * Main execution
 */
async function main() {
  console.log('üé¨ Starting Data Dictionary Creation')
  console.log(`   URL: ${DKAN_URL}`)
  console.log(`   Auth: ${DKAN_USER ? 'Enabled' : 'Disabled'}\n`)

  const client = new DkanApiClient({
    baseUrl: DKAN_URL,
    auth: DKAN_USER && DKAN_PASS
      ? { username: DKAN_USER, password: DKAN_PASS }
      : undefined,
  })

  try {
    // Fetch all distributions
    const distributions = await fetchDatasetsWithDistributions(client)

    if (distributions.length === 0) {
      console.log('‚ùå No CSV distributions found')
      return
    }

    let created = 0
    let skipped = 0
    let errors = 0

    console.log('üìñ Creating Data Dictionaries...\n')

    for (const distribution of distributions) {
      const distTitle = distribution.title || distribution.identifier
      console.log(`  ‚Üí ${distTitle}`)
      console.log(`    Dataset: ${distribution.datasetTitle}`)
      console.log(`    Distribution ID: ${distribution.identifier}`)

      if (!distribution.downloadURL) {
        console.log(`    ‚äò Skipped (no download URL)\n`)
        skipped++
        continue
      }

      // Analyze CSV file (normalize URL to use configured baseUrl)
      // Extract the path from the distribution URL and combine with base URL
      // This prevents double slashes and ensures proper URL construction
      const urlPath = distribution.downloadURL.replace(/^https?:\/\/[^/]+/, '')
      const normalizedBaseUrl = DKAN_URL.replace(/\/+$/, '') // Remove trailing slashes
      const downloadURL = normalizedBaseUrl + urlPath
      const fields = await analyzeCSV(downloadURL)

      if (!fields) {
        console.log(`    ‚äò Skipped (could not analyze CSV)\n`)
        skipped++
        continue
      }

      // Create dictionary
      const success = await createDataDictionary(client, distribution, fields)

      if (success) {
        console.log(`    ‚úì Created successfully\n`)
        created++
      } else {
        console.log(`    ‚úó Failed to create\n`)
        errors++
      }
    }

    // Summary
    console.log('============================================================')
    console.log('üìä Creation Summary')
    console.log('============================================================')
    console.log(`Total Distributions: ${distributions.length}`)
    console.log(`‚úì Created:          ${created}`)
    console.log(`‚äò Skipped:          ${skipped}`)
    console.log(`‚úó Errors:           ${errors}`)
    console.log('============================================================\n')

    if (created > 0) {
      console.log('‚úÖ Data dictionaries created successfully!')
      console.log(`   View them at: ${DKAN_URL}/admin/dkan/data-dictionary\n`)
    }
  } catch (error) {
    console.error('‚ùå Error:', error instanceof Error ? error.message : String(error))
    process.exit(1)
  }
}

main()
